MISC Startup Commands

##SCALA LOAD
$SPARK_HOME/bin/spark-shell --conf spark.cassandra.connection.host=cassandra0 --packages com.datastax.spark:spark-cassandra-connector_2.11:2.3.2

import com.datastax.spark.connector._
import org.apache.spark.sql.cassandra._

val rdd = sc.textFile("SMSSpamCollection.txt")
val split = rdd.map(line => line.split("\t"))
val finalRDD = split.map(arr => (UUIDs.random() ,arr (0),arr( 1 )))
finalRDD.saveToCassandra("exams", "spamdata", SomeColumns("key","spamkey", "spamtext"))


##sparkapp to load data 

import com.datastax.spark.connector._
import org.apache.spark.sql.cassandra._

object SimpleApp {
  def main(args) {
    val rdd = sc.textFile("SMSSpamCollection.txt")
    val split = rdd.map(line => line.split("\t"))
    val finalRDD = split.map(arr => ("uuid()",arr (0),arr( 1 )))
    finalRDD.saveToCassandra("exams", "spamdata", SomeColumns("key","spamkey", "spamtext"))
  }
}

spark.read.format("org.apache.spark.sql.cassandra").options(table="spamtext", keyspace="exams").load().show()


## Attempts to get Jobserver working
curl --data-binary @test1.jar localhost:8090/jars/test
curl -d "input.string = a b c a b see" "localhost:8090/jobs?appName=test&classPath=com.example.wordcount"