{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539329521286_-1366058643","id":"20181012-073201_326296712","dateCreated":"2018-10-12T07:32:01+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11848","text":"print (\"Source for ML related code: https://acadgild.com/blog/building-spam-filtering-engine-using-spark-mllib\")","dateUpdated":"2018-10-12T07:32:30+0000"},{"text":"import com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\n\nval spamRdd = sc.cassandraTable(\"exams\", \"spamdata\").select(\"spamtext\").where(\"spamkey= ?\",\"spam\")\nval hamRdd = sc.cassandraTable(\"exams\", \"spamdata\").select(\"spamtext\").where(\"spamkey= ?\",\"ham\")\n","user":"anonymous","dateUpdated":"2018-10-12T07:31:28+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\nspamRdd: com.datastax.spark.connector.rdd.CassandraTableScanRDD[com.datastax.spark.connector.CassandraRow] = CassandraTableScanRDD[170] at RDD at CassandraRDD.scala:19\nhamRdd: com.datastax.spark.connector.rdd.CassandraTableScanRDD[com.datastax.spark.connector.CassandraRow] = CassandraTableScanRDD[173] at RDD at CassandraRDD.scala:19\n"}]},"apps":[],"jobName":"paragraph_1539329432210_864234283","id":"20181009-121600_158674812","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9633","dateFinished":"2018-10-12T07:31:29+0000","dateStarted":"2018-10-12T07:31:28+0000"},{"text":"val spamNorm = spamRdd.map(row => row.getString(0))\nval hamNorm = hamRdd.map(row => row.getString(0))\n\n//val hamNorm\nspamNorm.take(5).foreach(println)\n","user":"anonymous","dateUpdated":"2018-10-12T07:31:31+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"spamNorm: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[174] at map at <console>:57\nhamNorm: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[175] at map at <console>:57\n"}]},"apps":[],"jobName":"paragraph_1539329432210_-1660797994","id":"20181009-123326_1619429411","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9634","dateFinished":"2018-10-12T07:31:32+0000","dateStarted":"2018-10-12T07:31:31+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.18.0.7:4040/jobs/job?id=77","http://172.18.0.7:4040/jobs/job?id=78","http://172.18.0.7:4040/jobs/job?id=79"],"interpreterSettingId":"spark"}}},{"text":"import org.apache.spark.mllib.feature.HashingTF \r\n\r\nval features = new HashingTF()\r\n","user":"anonymous","dateUpdated":"2018-10-12T07:31:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.feature.HashingTF\nfeatures: org.apache.spark.mllib.feature.HashingTF = org.apache.spark.mllib.feature.HashingTF@729f4bbc\n"}]},"apps":[],"jobName":"paragraph_1539329432211_-1326255295","id":"20181009-123552_831651514","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9635","dateFinished":"2018-10-12T07:31:33+0000","dateStarted":"2018-10-12T07:31:32+0000"},{"text":"val Features_spam = spamNorm.map(mail => features.transform(mail.split(\" \")))\r\nval Features_ham = hamNorm.map(mail => features.transform(mail.split(\" \")))\r\n","user":"anonymous","dateUpdated":"2018-10-12T07:31:34+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Features_spam: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[176] at map at <console>:62\nFeatures_ham: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[177] at map at <console>:62\n"}]},"apps":[],"jobName":"paragraph_1539329432211_-1758877488","id":"20181009-123652_1468312651","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9636","dateFinished":"2018-10-12T07:31:35+0000","dateStarted":"2018-10-12T07:31:34+0000"},{"text":"import org.apache.spark.mllib.regression.LabeledPoint\r\n\r\nval positive_data = Features_spam.map(features => LabeledPoint(1, features))\r\nval negative_data = Features_ham.map(features => LabeledPoint(0, features))\r\n","user":"anonymous","dateUpdated":"2018-10-12T07:31:36+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.regression.LabeledPoint\npositive_data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[178] at map at <console>:65\nnegative_data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[179] at map at <console>:65\n"}]},"apps":[],"jobName":"paragraph_1539329432211_-1724957911","id":"20181009-123742_1210514672","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9637","dateFinished":"2018-10-12T07:31:36+0000","dateStarted":"2018-10-12T07:31:36+0000"},{"text":"val data = positive_data.union(negative_data)\r\nval Array(training, test) = data.randomSplit(Array(0.65, 0.35))\r\n","user":"anonymous","dateUpdated":"2018-10-12T07:32:56+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = UnionRDD[180] at union at <console>:75\nres70: data.type = UnionRDD[180] at union at <console>:75\ntraining: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[181] at randomSplit at <console>:77\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[182] at randomSplit at <console>:77\n"}]},"apps":[],"jobName":"paragraph_1539329432211_-402362223","id":"20181009-124143_1828678095","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9638","dateFinished":"2018-10-12T07:31:38+0000","dateStarted":"2018-10-12T07:31:37+0000"},{"text":"import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD, NaiveBayes, LogisticRegressionWithSGD}\r\nval nb = new NaiveBayes()\r\n","user":"anonymous","dateUpdated":"2018-10-12T07:32:38+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD, NaiveBayes, LogisticRegressionWithSGD}\nwarning: there was one deprecation warning; re-run with -deprecation for details\nlogistic_Learner: org.apache.spark.mllib.classification.LogisticRegressionWithSGD = org.apache.spark.mllib.classification.LogisticRegressionWithSGD@4ff61e8f\n"}]},"apps":[],"jobName":"paragraph_1539329432211_-1072489960","id":"20181009-124238_59831507","dateCreated":"2018-10-12T07:30:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9639","dateFinished":"2018-10-12T07:31:39+0000","dateStarted":"2018-10-12T07:31:38+0000"},{"text":"val model = nb.run(training)\r\n\r\nval predictionLabel = test.map(x=> (model.predict(x.features),x.label))\r\n\r\nval accuracy = 1.0 * predictionLabel.filter(x => x._1 == x._2).count() / training.count()\r\n","user":"anonymous","dateUpdated":"2018-10-12T07:32:40+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.UnsupportedOperationException: empty collection\n  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1370)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.first(RDD.scala:1367)\n  at org.apache.spark.mllib.regression.GeneralizedLinearAlgorithm.generateInitialWeights(GeneralizedLinearAlgorithm.scala:204)\n  at org.apache.spark.mllib.regression.GeneralizedLinearAlgorithm.run(GeneralizedLinearAlgorithm.scala:234)\n  ... 72 elided\n"}]},"apps":[],"jobName":"paragraph_1539329432211_2101435814","id":"20181009-124303_1308818250","dateCreated":"2018-10-12T07:30:32+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:9640","dateFinished":"2018-10-12T07:31:41+0000","dateStarted":"2018-10-12T07:31:39+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.18.0.7:4040/jobs/job?id=80","http://172.18.0.7:4040/jobs/job?id=81","http://172.18.0.7:4040/jobs/job?id=82","http://172.18.0.7:4040/jobs/job?id=83"],"interpreterSettingId":"spark"}}},{"user":"anonymous","dateUpdated":"2018-10-12T07:30:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539329432212_280166357","id":"20181009-124314_80683080","dateCreated":"2018-10-12T07:30:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:9641"}],"name":"ML Analytics","id":"2DTMU69UQ","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}